import type { AIMessage, AISecurityReport, AIFinding, SecurityScore, VulnerabilityScanResult, AppRiskProfile } from '../models/types';

// AI model configuration
const GEMINI_MODEL = 'gemini-2.5-flash';

/**
 * Initialize the Gemini AI client
 */
function getAIClient() {
  const apiKey = (typeof process !== 'undefined' && process.env?.GEMINI_API_KEY) ||
    (typeof window !== 'undefined' && (window as any).__GEMINI_API_KEY__);

  if (!apiKey) return null;

  // Dynamic import for @google/genai
  return { apiKey };
}

/**
 * Generate an AI security report based on scan results
 */
export async function generateSecurityReport(params: {
  securityScore: SecurityScore;
  vulnerabilities: VulnerabilityScanResult;
  riskyApps: AppRiskProfile[];
  deviceInfo: { model: string; os: string; patchLevel: string };
}): Promise<AISecurityReport> {
  const config = getAIClient();
  if (!config) {
    return generateOfflineReport(params);
  }

  try {
    const { GoogleGenAI } = await import('@google/genai');
    const ai = new GoogleGenAI({ apiKey: config.apiKey });

    const prompt = `You are an expert mobile security analyst. Analyze this device security data and provide a comprehensive security report.

Device: ${params.deviceInfo.model} running ${params.deviceInfo.os} (Patch Level: ${params.deviceInfo.patchLevel})
Security Score: ${params.securityScore.overall}/100 (Grade: ${params.securityScore.grade})

Score Breakdown:
- OS Version: ${params.securityScore.breakdown.osVersion}/100
- Patch Level: ${params.securityScore.breakdown.patchLevel}/100
- Permissions: ${params.securityScore.breakdown.permissions}/100
- Network Security: ${params.securityScore.breakdown.networkSecurity}/100
- App Security: ${params.securityScore.breakdown.appSecurity}/100
- Stalkerware Risk: ${params.securityScore.breakdown.stalkerwareRisk}/100

Vulnerabilities Found: ${params.vulnerabilities.totalFound}
- Critical: ${params.vulnerabilities.criticalCount}
- High: ${params.vulnerabilities.highCount}
- Medium: ${params.vulnerabilities.mediumCount}
- Low: ${params.vulnerabilities.lowCount}

Top CVEs: ${params.vulnerabilities.vulnerabilities.slice(0, 5).map((v) => `${v.id} (${v.severity}): ${v.description}`).join('\n')}

Risky Apps: ${params.riskyApps.length}
${params.riskyApps.slice(0, 5).map((a) => `- ${a.appName} (Risk: ${a.riskLevel}, Score: ${a.riskScore})`).join('\n')}

Provide your analysis in the following JSON format:
{
  "summary": "2-3 sentence executive summary",
  "riskLevel": "LOW|MEDIUM|HIGH|CRITICAL",
  "findings": [{"title": "", "description": "", "severity": "INFO|LOW|MEDIUM|HIGH|CRITICAL", "remediation": "", "category": ""}],
  "recommendations": ["actionable step 1", "actionable step 2", ...],
  "attackSurface": "Description of the overall attack surface"
}`;

    const response = await ai.models.generateContent({
      model: GEMINI_MODEL,
      contents: prompt,
      config: {
        responseMimeType: 'application/json',
        temperature: 0.3,
      },
    });

    const text = response.text || '';
    const parsed = JSON.parse(text);
    return {
      ...parsed,
      generatedAt: new Date().toISOString(),
    };
  } catch (error) {
    console.error('AI report generation failed:', error);
    return generateOfflineReport(params);
  }
}

/**
 * Chat with the AI security assistant
 */
export async function chatWithAssistant(
  messages: AIMessage[],
  context?: {
    securityScore?: SecurityScore;
    deviceInfo?: { model: string; os: string };
  }
): Promise<string> {
  const config = getAIClient();
  if (!config) {
    return 'AI assistant is unavailable. Please configure your API key to enable AI-powered security analysis.';
  }

  try {
    const { GoogleGenAI } = await import('@google/genai');
    const ai = new GoogleGenAI({ apiKey: config.apiKey });

    const systemPrompt = `You are ExploitGuard AI, an expert mobile security assistant. You help users understand security vulnerabilities, protect their devices, and make informed decisions about app permissions and privacy.

Your capabilities:
- Explain CVEs and vulnerabilities in plain language
- Advise on app permission management
- Help users understand phishing and social engineering threats
- Provide security hardening recommendations
- Analyze suspicious URLs, files, and app behaviors
- Educate users about mobile security best practices

${context?.securityScore ? `Current device security score: ${context.securityScore.overall}/100 (${context.securityScore.grade})` : ''}
${context?.deviceInfo ? `Device: ${context.deviceInfo.model} running ${context.deviceInfo.os}` : ''}

Be concise, actionable, and avoid unnecessary jargon. When discussing vulnerabilities, always include severity and remediation steps.`;

    const chatHistory = messages.map((m) => ({
      role: m.role === 'assistant' ? 'model' : m.role,
      parts: [{ text: m.content }],
    }));

    const response = await ai.models.generateContent({
      model: GEMINI_MODEL,
      contents: [
        { role: 'user', parts: [{ text: systemPrompt }] },
        { role: 'model', parts: [{ text: 'I\'m ExploitGuard AI, ready to help you with mobile security. What would you like to know?' }] },
        ...chatHistory,
      ],
      config: {
        temperature: 0.7,
        maxOutputTokens: 1024,
      },
    });

    return response.text || 'I could not generate a response. Please try again.';
  } catch (error) {
    console.error('AI chat failed:', error);
    return 'An error occurred while communicating with the AI assistant. Please try again later.';
  }
}

/**
 * AI-powered app risk assessment
 */
export async function assessAppRisk(appInfo: {
  name: string;
  packageName: string;
  permissions: string[];
  description?: string;
}): Promise<{ riskScore: number; assessment: string; concerns: string[] }> {
  const config = getAIClient();
  if (!config) {
    return {
      riskScore: 50,
      assessment: 'Unable to perform AI assessment. Based on permissions alone, this app requires review.',
      concerns: appInfo.permissions.filter((p) =>
        ['camera', 'microphone', 'location', 'contacts', 'sms', 'phone'].some((d) => p.toLowerCase().includes(d))
      ),
    };
  }

  try {
    const { GoogleGenAI } = await import('@google/genai');
    const ai = new GoogleGenAI({ apiKey: config.apiKey });

    const prompt = `Analyze this mobile app for security risks:

App: ${appInfo.name}
Package: ${appInfo.packageName}
Permissions: ${appInfo.permissions.join(', ')}
${appInfo.description ? `Description: ${appInfo.description}` : ''}

Respond in JSON:
{
  "riskScore": 0-100,
  "assessment": "brief assessment",
  "concerns": ["concern 1", "concern 2"]
}`;

    const response = await ai.models.generateContent({
      model: GEMINI_MODEL,
      contents: prompt,
      config: {
        responseMimeType: 'application/json',
        temperature: 0.3,
      },
    });

    return JSON.parse(response.text || '{}');
  } catch {
    return {
      riskScore: 50,
      assessment: 'AI assessment unavailable.',
      concerns: [],
    };
  }
}

/**
 * Generate an offline report when AI is unavailable
 */
function generateOfflineReport(params: {
  securityScore: SecurityScore;
  vulnerabilities: VulnerabilityScanResult;
  riskyApps: AppRiskProfile[];
  deviceInfo: { model: string; os: string; patchLevel: string };
}): AISecurityReport {
  const findings: AIFinding[] = [];

  if (params.securityScore.overall < 50) {
    findings.push({
      title: 'Low Security Score',
      description: `Your device scored ${params.securityScore.overall}/100, indicating significant security concerns.`,
      severity: 'HIGH',
      remediation: 'Update your OS and apps, review permissions, and install security patches.',
      category: 'Overall Security',
    });
  }

  if (params.vulnerabilities.criticalCount > 0) {
    findings.push({
      title: 'Critical Vulnerabilities Detected',
      description: `${params.vulnerabilities.criticalCount} critical CVEs affect your device.`,
      severity: 'CRITICAL',
      remediation: 'Apply the latest security patch immediately.',
      category: 'Vulnerabilities',
    });
  }

  if (params.vulnerabilities.highCount > 0) {
    findings.push({
      title: 'High-Severity Vulnerabilities',
      description: `${params.vulnerabilities.highCount} high-severity vulnerabilities found.`,
      severity: 'HIGH',
      remediation: 'Update to the latest available security patch level.',
      category: 'Vulnerabilities',
    });
  }

  params.riskyApps.forEach((app) => {
    if (app.riskLevel === 'DANGEROUS' || app.isStalkerware) {
      findings.push({
        title: `Dangerous App: ${app.appName}`,
        description: `${app.appName} has a risk score of ${app.riskScore}/100.${app.isStalkerware ? ' Identified as potential stalkerware.' : ''}`,
        severity: app.isStalkerware ? 'CRITICAL' : 'HIGH',
        remediation: `Uninstall ${app.appName} immediately.`,
        category: 'Malicious Apps',
      });
    }
  });

  const riskLevel = params.securityScore.overall >= 70 ? 'LOW' :
    params.securityScore.overall >= 50 ? 'MEDIUM' :
    params.securityScore.overall >= 30 ? 'HIGH' : 'CRITICAL';

  return {
    summary: `Your ${params.deviceInfo.model} running ${params.deviceInfo.os} has a security score of ${params.securityScore.overall}/100. ${params.vulnerabilities.totalFound} vulnerabilities and ${params.riskyApps.length} risky apps were detected.`,
    riskLevel: riskLevel as AISecurityReport['riskLevel'],
    findings,
    recommendations: [
      'Update your device to the latest security patch',
      'Review and revoke unnecessary app permissions',
      'Remove any apps flagged as dangerous or stalkerware',
      'Enable device encryption if not already active',
      'Use strong screen lock authentication',
    ],
    attackSurface: `${params.vulnerabilities.totalFound} known vulnerabilities with ${params.riskyApps.length} risky applications create a ${riskLevel.toLowerCase()}-risk attack surface.`,
    generatedAt: new Date().toISOString(),
  };
}
